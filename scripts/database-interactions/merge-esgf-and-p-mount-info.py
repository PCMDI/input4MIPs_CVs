"""
Merge the information scraped from ESGF and the files

The ESGF data is scraped by Paul.
The file data is generated by input4mips-validation.
TODO: move scripts for both these processes into here,
or automate the processes and document where that automation happens.
"""

from __future__ import annotations

from pathlib import Path
from typing import Any

import json

import pandas as pd
import pandas_diff as pd_diff
import tqdm

import typer


def apply_fixes_to_pmount_data(inp: pd.DataFrame) -> pd.DataFrame:
    """
    Apply manual fixes to our pmount extracted data

    Hopefully we can turn this into a no-op once that process is working smoothly.
    """
    res = inp.copy()

    # The validation column is not handled properly yet by input4mips-validation,
    # so set it manually here
    res.loc[
        res["source_id"].isin(["PCMDI-AMIP-1-1-9", "MRI-JRA55-do-1-6-0"]),
        "validated_input4mips",
    ] = True

    # Note, updates to all other fields happen as part of the merge process

    return res


def merge_pmount_and_esgf_data(
    pmount_df: pd.DataFrame, esgf_raw: dict[str, Any]
) -> pd.DataFrame:
    res = pmount_df.copy()

    for idx, row in tqdm.tqdm(res.iterrows()):
        if row.esgf_dataset_master_id not in esgf_raw:
            # Data not in ESGF yet
            # Print info and move in
            print(f"{row.esgf_dataset_master_id} is not in our ESGF records yet")

            continue

        esgf_dataset_info = esgf_raw[row.esgf_dataset_master_id]

        # Grab info of interest from the ESGF records
        esgf_field_db_field_map = {
            "_timestamp": "timestamp",
            "data_node": "data_node",
            "latest": "latest",
            "replica": "replica",
            # Have to work out what this field should be before handling
            # "xlink": "xlink",
        }
        for esgf_field, db_field in esgf_field_db_field_map.items():
            res.loc[idx, db_field] = esgf_dataset_info[esgf_field]

        if esgf_dataset_info["latest"]:
            res.loc[idx, "publication_status"] = "published"

        else:
            # Not sure if this logic is correct, but we can start like this
            # and then interate.
            res.loc[idx, "publication_status"] = "retracted"

    return res


def print_diffs(start: pd.DataFrame, end: pd.DataFrame) -> None:
    """
    Print the difference in our database start before and after the merge
    """
    print("Creating diffs")
    diffs = pd_diff.get_diffs(start, end, ["source_id", "tracking_id"])

    for _, row in diffs.iterrows():
        if row["operation"] == "create":
            print(f"Added entry for {row['object_values']}")

        elif row["operation"] == "modify":
            print(
                f"For entry {row['object_values']}, "
                f"modified {row['attribute_changed']} "
                f"from {row['old_value']} to {row['new_value']}"
            )

        else:
            raise NotImplementedError()

    # Could save diffs here too I guess, for later parsing...


def main(create_diffs: bool = True) -> None:
    """
    Merge the information scraped from ESGF and the files
    """
    DB_DIR = Path(__file__).parents[2] / "DatasetsDatabase"

    DB_FILE = DB_DIR / "input4MIPs_datasets.json"
    """Output database file"""

    with open(DB_DIR / DB_FILE, "r") as fh:
        db_start_raw = json.load(fh)

    db_start_df = pd.DataFrame(db_start_raw)

    with open(DB_DIR / "input-data" / "pmount.json") as fh:
        pmount_raw = json.load(fh)

    with open(DB_DIR / "input-data" / "esgf.json") as fh:
        esgf_raw = json.load(fh)

    pmount_df = apply_fixes_to_pmount_data(pd.DataFrame(pmount_raw))

    db_df = merge_pmount_and_esgf_data(pmount_df=pmount_df, esgf_raw=esgf_raw)

    if create_diffs:
        print_diffs(start=db_start_df, end=db_df)

    with open(DB_FILE, "w") as fh:
        json.dump(
            db_df.to_dict(orient="records"),
            fh,
            ensure_ascii=True,
            sort_keys=True,
            indent=4,
            separators=(",", ":"),
        )

    print(f"Update {DB_FILE}")


if __name__ == "__main__":
    typer.run(main)
